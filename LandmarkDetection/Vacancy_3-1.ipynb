{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f64689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import natsort\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import io\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb31d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,num_classes=136):\n",
    "        super().__init__()\n",
    "        self.model_name='resnet34'\n",
    "        self.model=models.resnet34(pretrained=True)\n",
    "        self.model.conv1=nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=2, bias=False)\n",
    "        #self.model.conv1=nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        #self.model.conv1=nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.model.fc=nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.model(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20fc7c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :  16.834146976470947  for  36  Frames\n"
     ]
    }
   ],
   "source": [
    "net = cv2.dnn.readNetFromCaffe('./openCV_models/deploy.prototxt.txt',\n",
    "                               './openCV_models/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "network = Network()\n",
    "network.cuda()\n",
    "network.load_state_dict(torch.load('./Vacancy_16.pth'))\n",
    "network.eval()\n",
    "\n",
    "save_dir = './Vacancy_temp'\n",
    "\n",
    "start = time.time()\n",
    "imgs_dir = './Pictures/Camera Roll/*.jpg'\n",
    "imgs = glob.glob(imgs_dir)\n",
    "imgs = natsort.natsorted(imgs)\n",
    "fig = []\n",
    "i = 0\n",
    "widthh = 0; heightt = 0; tt = 0; ll = 0;\n",
    "for i in range(len(imgs)) :\n",
    "    frame = cv2.imread(imgs[i], 1)\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300,300)), 1.0, (300,300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])\n",
    "    (l, t, r, b) = box.astype(\"int\")\n",
    "    # Crop\n",
    "    width = (r-l)\n",
    "    height = (b-t)\n",
    "    if(width > height) :\n",
    "        widthh = width*1.5\n",
    "        heightt = widthh\n",
    "        tt = t + height*0.5 - heightt*0.5\n",
    "        ll = l - width*0.25\n",
    "    else :\n",
    "        heightt = height*1.5\n",
    "        widthh = heightt\n",
    "        tt = t - height*0.25\n",
    "        ll = l + width*0.5 - widthh*0.5\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = TF.crop(frame, tt, ll, heightt, widthh)\n",
    "    frame = TF.resize(frame, (224,224))\n",
    "    frame = TF.to_tensor(frame)\n",
    "    frame = TF.normalize(frame, [0.5], [0.5])\n",
    "    frame = frame.unsqueeze(1)\n",
    "    frame = frame.cuda()\n",
    "    \n",
    "    predictions = (network(frame).cpu())\n",
    "    predictions = predictions.view(-1, 68, 2)\n",
    "    \n",
    "    fig.insert(i, plt.figure(figsize=(600/100, 600/100), dpi=100))\n",
    "    plt.scatter(predictions[0, :, 0].detach().numpy(), predictions[0, :, 1].detach().numpy(), c = 'red', s = 10)\n",
    "    plt.imshow(frame.cpu().squeeze(), cmap='gray')\n",
    "    plt.savefig(save_dir + '/' + str(i) + '.jpg')\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"Time : \" , time.time()-start, \" for \", i , \" Frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ba518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
